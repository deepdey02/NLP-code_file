{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebd1161d-0888-48dd-a38b-fc5b324555a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\deep\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: click in c:\\users\\deep\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\deep\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\deep\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\deep\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\deep\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Using cached nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.9.1\n",
      "    Uninstalling nltk-3.9.1:\n",
      "      Successfully uninstalled nltk-3.9.1\n",
      "Successfully installed nltk-3.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0419199f-61ca-4642-904c-7350ab478314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "801ce478-ce1e-4a56-8f95-db526f93be60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Deep\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Deep\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b188a450-e7a7-4c9d-b2e2-8685dbf57d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'world', '!']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text = \"Hello world!\"\n",
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "583872cd-ea2a-441a-b781-06d3739f5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce9d6d31-20b8-45f6-b2b1-2c80c3511971",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"Hello, I am Deep Dey. I live in Mumbai. I Study in Imarticus.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f323cb89-c306-414a-b2f4-fb860ed431e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Deep Dey. I live in Mumbai. I Study in Imarticus.\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "985bda26-4bae-4107-a798-fbfbebbe8ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " ',',\n",
       " 'I',\n",
       " 'am',\n",
       " 'Deep',\n",
       " 'Dey',\n",
       " '.',\n",
       " 'I',\n",
       " 'live',\n",
       " 'in',\n",
       " 'Mumbai',\n",
       " '.',\n",
       " 'I',\n",
       " 'Study',\n",
       " 'in',\n",
       " 'Imarticus',\n",
       " '.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89745a86-8926-4727-b68f-bfde37e57029",
   "metadata": {},
   "source": [
    "======================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae335a5e-ec0d-4fc7-b38b-d71c717d540b",
   "metadata": {},
   "source": [
    "========================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "860e20b8-3446-48ae-abf7-12adb6ae1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66fac42c-2a4b-432a-995a-617223f3261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ca3991c3-07a5-4a33-b0f5-624ffbf0e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ['Study','Studying','Studied', 'Studier', 'Studies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b956928c-1500-4e85-ab43-10f9e50ebdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['studi', 'studi', 'studi', 'studier', 'studi']\n"
     ]
    }
   ],
   "source": [
    "stems = [ps.stem(word) for word in b]\n",
    "print(stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b39d856-7b50-4dc4-afa0-f65fa0dd5fe2",
   "metadata": {},
   "source": [
    "# OR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "761cd0e2-f3e0-49f9-83c0-a862532df206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study :  studi\n",
      "Studying :  studi\n",
      "Studied :  studi\n",
      "Studier :  studier\n",
      "Studies :  studi\n"
     ]
    }
   ],
   "source": [
    "for i in b:\n",
    "    print(i, \": \", ps.stem(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf4ea3a-e917-435c-b801-b7eebb8ee670",
   "metadata": {},
   "source": [
    "======================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f6bbdc-2cef-402f-916f-c1b8beac3655",
   "metadata": {},
   "source": [
    "======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "39984f74-8700-46d2-be7b-83642ceb9148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6dfb4a21-6ab7-45ff-96a6-46657a92d5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "wn = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2928f0a9-855a-4162-b1cc-79644f611bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = ['best', 'better', 'worst', 'running']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d866ba2a-bf5d-4477-b55e-597b403e6602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Deep\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ba4ae1b9-9e73-4a5c-bb43-573ca384509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = [wn.lemmatize(i) for i in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "39813da0-c041-454d-8ad7-a3c1d4d9c3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized:  ['best', 'better', 'worst', 'running']\n"
     ]
    }
   ],
   "source": [
    "print('Lemmatized: ', wnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c1155df7-756e-402a-9d5d-d7620bd2fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = [wn.lemmatize(i, pos='a') for i in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fb0ad373-3189-4731-97ce-57d548b3118d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatized: ['best', 'good', 'bad', 'running']\n"
     ]
    }
   ],
   "source": [
    "print('Lemmatized:', wnl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fb290e54-a63c-4584-b90b-ede0b2a16eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = [wn.lemmatize(i, pos='v') for i in c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4df00-ce80-4f8f-837d-8b78f71f8094",
   "metadata": {},
   "source": [
    "================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4801da-28cd-4dfb-8672-cec4e853b250",
   "metadata": {},
   "source": [
    "================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "62e1367e-c667-4315-a109-f457cf8d667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 'Natural language processing(NLP) is a branch of Artificial intelligence(AI) that enables many parts.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d3a17467-cbae-43c4-b42e-2d6013e9dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = word_tokenize(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9e9e000a-59bd-4f67-9355-4c631cea62b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Deep\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1244737a-6897-454c-af2e-938a34368300",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nltk.pos_tag(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0ee72343-559a-4ca1-b7e3-52dd5c596481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Deep\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0928c996-9e54-4ac9-a0ff-b963fe44b1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS: [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('a', 'DT'), ('branch', 'NN'), ('of', 'IN'), ('Artificial', 'JJ'), ('intelligence', 'NN'), ('(', '('), ('AI', 'NNP'), (')', ')'), ('that', 'IN'), ('enables', 'VBZ'), ('many', 'JJ'), ('parts', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print('POS:', pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c048f9f8-f750-437f-9e8e-54c2a8988cca",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d551ea-d3da-42d6-851c-fb9fb371ec1f",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5e45719d-5b66-4a28-bc9b-d5f02fe4836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bad41a54-3bc8-4c4b-818f-ebcc21c5319f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Deep\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "09394ead-151b-4e11-93fa-622059ef205b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tokenization', 'is', 'the', 'process', 'of', 'breaking', 'text', 'into', 'words', 'or', 'phrases', '.']\n"
     ]
    }
   ],
   "source": [
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "input_text = \"Tokenization is the process of breaking text into words or phrases.\"\n",
    "tokens = tokenize_text(input_text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "467fb3f2-cb5a-43c6-be5d-2d3b29204c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tokenization', 'is', 'the', 'process', 'of', 'breaking', 'text', 'into', 'words', 'or', 'phrases']\n"
     ]
    }
   ],
   "source": [
    "def remove_non_alphabets(tokens):\n",
    "    return[token for token in tokens if token.isalpha()]\n",
    "alphabetic_tokens = remove_non_alphabets(tokens)\n",
    "print(alphabetic_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7de7c4-97f3-4d2a-8c2b-d80171771146",
   "metadata": {},
   "source": [
    "======================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210541be-3ae1-4e96-9119-388f2f26bffc",
   "metadata": {},
   "source": [
    "========================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "98d10cc8-ab1d-4353-9e14-b7e61c0fe56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "235e37c4-2e8b-45a7-957c-48d4fbebbcef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tokenization', 'process', 'breaking', 'text', 'words', 'phrases']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Deep\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return[token for token in tokens if token.lower() not in stop_words]\n",
    "\n",
    "filtered_tokens = remove_stopwords(alphabetic_tokens)\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35cd369-4043-40a4-bffc-42e3da8203d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9f4776da-e0b5-4efe-b1f0-7e0c5650bf28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 1 1]\n",
      " [2 0 1 1 1 1]]\n",
      "['document' 'first' 'is' 'second' 'the' 'this']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def create_bag_of_words(texts):\n",
    "    vectorizer = CountVectorizer()\n",
    "    bag_of_words = vectorizer.fit_transform(texts)\n",
    "    return bag_of_words, vectorizer.get_feature_names_out()\n",
    "\n",
    "texts = [\"This is the first document.\", \"This document is the second document.\"]\n",
    "bag_of_words, feature_names = create_bag_of_words(texts)\n",
    "\n",
    "print(bag_of_words.toarray())\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eecca1b-507d-4a36-b6d4-a55db0ffaa13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
